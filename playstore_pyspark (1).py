# -*- coding: utf-8 -*-
"""playstore_pyspark.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1pMroQt0oGh_XKmU3dmiELJZKyH359oI9
"""


from pyspark.sql import SparkSession
import pandas as pd
import matplotlib.pyplot as plt #data visualization
from pyspark.sql.functions import col, regexp_replace, when #for datacleaning
spark = SparkSession.builder.appName("test_spark").getOrCreate() #create a session

df= spark.read.csv("googleplaystore.csv",header=True,inferSchema=True) #Read the csv and load it into dataframe

df.createOrReplaceTempView("apps")

df.printSchema()

df.show()

#DATA CLEANING CODE
# 1. Drop rows with null 'App' values
df = df.dropna(subset=['App'])

# 2. Fill null values for 'Category' with a default value 'Unknown'
df = df.fillna({'Category': 'Unknown'})

# 3. Convert 'Rating' to float
df = df.withColumn("Rating", col("Rating").cast("float"))

# 4. Convert 'Reviews' to integer
df = df.withColumn("Reviews", col("Reviews").cast("integer"))

# 5. Remove 'M' from 'Size' and convert to float (assuming size is in MB)
df = df.withColumn("Size", regexp_replace("Size", "M", "").cast("float"))

# 6. Remove '+' and ',' from 'Installs' and convert to integer
df = df.withColumn("Installs", regexp_replace(regexp_replace("Installs", "\\+", ""), ",", "").cast("integer"))

# 7. Convert 'Price' to float (remove '$' for conversion)
df = df.withColumn("Price", when(col("Price") == "0", 0.0).otherwise(regexp_replace("Price", "\\$", "").cast("float")))

# 8. Standardize 'Last Updated' to a date format
df = df.withColumn("Last Updated", regexp_replace("Last Updated", " ", "-").cast("date"))

# 9. Fill null values for other columns with appropriate defaults
df = df.fillna({
    "Rating": 0.0,
    "Reviews": 0,
    "Size": 0.0,
    "Installs": 0,
    "Price": 0.0,
    "Content Rating": "Unknown",
    "Genres": "Unknown",
    "Last Updated": "2000-01-01",
    "Current Ver": "Unknown",
    "Android Ver": "Unknown"
})

# Show cleaned DataFrame
df.show()

#compute the total number of reviews for each app and then sort the apps by the total number of reviews in descending order
total_reviews = spark.sql("SELECT App, SUM(Reviews) as Total_Reviews FROM apps GROUP BY 1 ORDER BY 2 DESC")

total_reviews.show()

#calculates the total number of installs for each app and its corresponding category, then orders the results by the total number of installs in descending order.
No_of_Installs = spark.sql("SELECT App, Category, SUM(Installs) as No_of_Installs FROM apps GROUP BY App, Category ORDER BY No_of_Installs DESC")

No_of_Installs.show()

#calculates the total number of installs for each app and orders the results by the total number of installs in descending order
No_of_Installs = spark.sql("SELECT App, SUM(Installs) as No_of_Installs FROM apps GROUP BY App ORDER BY No_of_Installs DESC")

No_of_Installs.show()

#names and prices of all paid apps in your dataset.
paid_apps = spark.sql("SELECT App, Price FROM apps WHERE `Type` = 'Paid'")
paid_apps.show()

#display the names and ratings of all apps in dataset that have ratings between 4 and 4.5 inclusive.
selected_apps = spark.sql("SELECT App, Rating FROM apps WHERE Rating BETWEEN 4 AND 4.5")
selected_apps.show()

#display the names and number of installs of the top 5 apps with the highest number of installs in dataset.
top_5_apps = spark.sql("SELECT App, Installs FROM apps ORDER BY Installs DESC LIMIT 5")
top_5_apps.show()

#display the names and number of reviews of the top 10 apps with the highest number of reviews in dataset.
top_10_apps = spark.sql("SELECT App, Reviews FROM apps ORDER BY Reviews DESC LIMIT 10")
top_10_apps.show()

# Create a new DataFrame with the count of apps in each category
category_counts = df.groupBy('Category').count().orderBy('count', ascending=False)

# Convert the PySpark DataFrame to a Pandas DataFrame for plotting
category_counts_pd = category_counts.toPandas()

# Plotting the data
plt.figure(figsize=(12, 6))
plt.bar(category_counts_pd['Category'], category_counts_pd['count'], color='skyblue')
plt.xlabel('Category')
plt.ylabel('Number of Applications')
plt.title('Number of Applications in Each Category')
plt.xticks(rotation=90)
plt.show()

# Create a new DataFrame with the count of apps in each Content Rating
content_rating_counts = spark.sql("SELECT `Content Rating`, COUNT(*) as AppCount FROM apps GROUP BY `Content Rating`")

# Show the table
content_rating_counts.show()

# Run an SQL query to get the distribution of app ratings
# The query rounds the ratings to the nearest integer, counts the number of apps for each rounded rating,
# groups by the rounded rating, and orders the results by the rounded rating
ratings_distribution = spark.sql("SELECT ROUND(Rating) AS RoundedRating, COUNT(*) AS Count FROM apps GROUP BY ROUND(Rating) ORDER BY RoundedRating")
ratings_distribution_pd = ratings_distribution.toPandas()

plt.figure(figsize=(12, 6))
plt.bar(ratings_distribution_pd['RoundedRating'], ratings_distribution_pd['Count'], color='skyblue')
plt.xlabel('Rating')
plt.ylabel('Number of Apps')
plt.title('Distribution of App Ratings')
plt.show()

#The query groups the data by 'Type' (Free or Paid) and sums the 'Installs' for each type
installs_comparison = spark.sql("SELECT Type, SUM(Installs) AS TotalInstalls FROM apps GROUP BY Type")
installs_comparison.show()

# The query filters the data to include only apps in the 'EDUCATION' category,
# groups the data by 'Genres', and counts the number of apps in each genre
education_apps_genres = spark.sql("SELECT Genres, COUNT(*) AS AppCount FROM apps WHERE Category = 'EDUCATION' GROUP BY Genres")
education_apps_genres_pd = education_apps_genres.toPandas()

plt.figure(figsize=(12, 6))
plt.bar(education_apps_genres_pd['Genres'], education_apps_genres_pd['AppCount'], color='skyblue')
plt.xlabel('Genres')
plt.ylabel('Number of Apps')
plt.title('Number of Apps per Genre in the Education Category')
plt.xticks(rotation=90)
plt.show()

#shows the maximum of categories
max_price_by_category = spark.sql("SELECT Category, MAX(Price) AS MaxPrice FROM apps GROUP BY Category")
max_price_by_category.show()

# Aggregate the data
category_counts = df.groupBy('Category').count().orderBy('count', ascending=False)
content_rating_counts = df.groupBy('Content Rating').count().orderBy('count', ascending=False)

# Convert PySpark DataFrame to Pandas DataFrame
category_counts_pd = category_counts.toPandas()
content_rating_counts_pd = content_rating_counts.toPandas()

# Create a pie chart for the number of apps in each category
plt.figure(figsize=(12, 6))
plt.pie(category_counts_pd['count'], labels=category_counts_pd['Category'], autopct='%1.1f%%', startangle=140)
plt.axis('equal')  # Equal aspect ratio ensures that pie is drawn as a circle
plt.title('Distribution of Apps by Category')
plt.show()

# Create a pie chart for the distribution of apps by content rating
plt.figure(figsize=(8, 8))
plt.pie(content_rating_counts_pd['count'], labels=content_rating_counts_pd['Content Rating'], autopct='%1.1f%%', startangle=90)
plt.axis('equal')
plt.title('Distribution of Apps by Content Rating')
plt.show()